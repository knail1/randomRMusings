#ISyE6501x GT Introduction to Analytics Modeling
#Week 1 Homework
#Date: 05/18/2018

#install the kernlab package
install.packages("kernlab")
#load the kernlab package
library(kernlab)
#install the kknn package
install.packages("kknn")
#load the kknn package
library(kknn)
#check the current working directory
getwd()


#-------Question 2.2.1----------------

#Clear environment
rm(list=ls())
#load data
data<-read.table("2.2credit_card_data-headersSummer2018.txt",header = T,sep='\t')
#see the total row numbers and total column numbers of the data
nrow(data)
ncol(data)
#Call ksvm using Vanilladot, which is a simple linear kernel.
model <-ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc", 
             kernel="vanilladot", C=100, scaled=TRUE)
model
#Calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
#Calculate a0
a0 <--model@b
a0
#see what the model predicts
pred <- predict(model, data[,1:10])
pred
#the actual response from the data
data[,11]
#fraction of the model's predictions match the actual classificationï¼š0.8639144
accuracy_1 <- sum(pred == data[,11]) / nrow(data)
accuracy_1

#-------Question 2.2.2-------------

#Clear environment
rm(list=ls())
#import data
data <- read.table("2.2credit_card_data-headersSummer2018.txt", header = TRUE, sep = '\t')
#Call ksvm using Gaussian, which is a non-linear kernel.
model1 <-ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc", 
             kernel="rbfdot", C=100, scaled=TRUE)
#set Gaussian with sigma as 1
rbfdot(sigma = 1)
# show the predict using model1
pred1 <- predict(model1, data[, 1:10])
pred1
#see the fraction of the model's predications match the actual classification
accuracy_2 <- sum(pred1 == data[, 11])/ (nrow(data))
accuracy_2
#result indicates the fraction of 0.9525994, better than the vanilladot kernel.


#----------Question 2.2.3--------------

#Clear environment
rm(list=ls())
#import data
data <- read.table("2.2credit_card_data-headersSummer2018.txt", header = TRUE, sep = '\t')
#Predict using kknn function. 
pred_knn <- rep(0, (nrow(data)))
for (i in 1:nrow(data)) {
    model_knn = kknn(R1 ~., data[-i, ], data[i, ], k=12, scale = TRUE)
    #round off to 0 or 1
    pred_knn[i] <- as.integer(fitted(model_knn)+0.5) 
}
accuracy_3 <- sum(pred_knn == data$R1) / nrow(data)
accuracy_3
#Tried k=3, accuracy=81.5%; 
#Tried k=6, accuracy=84.56%;
#Tried k=10, accuracy = 85.01%;
#Tried k=11, accuracy = 85.17%;
#Tried k=12, accuracy = 85.32%;
#Tried k=13, accuracy = 85.17%;
#Therefore, when k=12, the model will well classify the data 
#with the 0.853211 fraction of predications match the actual classification 


#---------Question 3.1.(a)----------------

#Clear environment
rm(list=ls())
#import data
data <- read.table("2.2credit_card_data-headersSummer2018.txt", header = TRUE, sep = '\t')
#check the number of rows and columns
nrow(data)
ncol(data)
#Setting seed to produce reproducible results
set.seed(1)
#set R1 data as factor
data$R1 <- as.factor(data$R1)

#Using leave one out cross-validation to find the optimal value of 'k'
fit_a <- train.kknn(R1 ~., data = data, kmax = 100, kernel = "optimal", scale = TRUE)
fit_a
#Value of 'k' with minimum missclassification error rate is 12.

#predict the model
pred_a <- predict(fit_a, data)
pred_a
#Finding the prediction accuracy
pred_accuracy_a <- sum(pred_a == data$R1)/nrow(data)
pred_accuracy_a
#predict accuracy is 0.9159021


#-----------Question 3.1.(b)------------

#Clear environment
rm(list=ls())
#import data
data <- read.table("2.2credit_card_data-headersSummer2018.txt", header = TRUE, sep = '\t')
#check the number of rows and columns
m <- nrow(data)
ncol(data)
#Setting seed to produce reproducible results
set.seed(1)
#set R1 data as factor
data$R1 <- as.factor(data$R1)

#Randomly selecting 1/2 of total indexes among 654 indexes for the train data
val_train <- sample(1:m, size = round(m/2), replace = FALSE)
#Randomly selecting 1/4 of total indexes for validation data and 1/4 of total indexes for testing data
val_rest_data <- data[-val_train, ] 
n <- nrow(val_rest_data)
val_val <- sample(1:n, size = round(n/2), replace = FALSE)
#Train data, validation data, and test data
train_data <- data[val_train, ]
valid_data <- data[val_val, ]
test_data <- data[-val_val, ]

#Using leave one out cross-validation to find the optimal value of 'k'
#tested both kernel as "optimal" and "rectangular"
#the misclassification is minimal when kernel ="rectangular" 
#Minimal misclassification=0.146789, k = 3
fit_b <- train.kknn(R1~., data = train_data, kmax = 100, kernel = "rectangular", scale = TRUE)
plot(fit_b)

#Testing the model on validation data set
pred_val <- predict(fit_b, valid_data)
#Finding the prediction accuracy, accuracy on validation data set is 0.8536585
pred_accuracy_val <- sum(pred_val == valid_data$R1)/nrow(valid_data)
pred_accuracy_val

#Testing the model on test data set
pred_test <- predict(fit_b, test_data)
#Finding the prediction accuracy, accuracy on test data set is 0.8795918
pred_accuracy_test <- sum(pred_test == test_data$R1)/nrow(test_data)
pred_accuracy_test

#Comparing the accuracy of pred_accuracy_val=0.8536585 and pred_accuracy_test=0.8795918, 
#the result is fairly consistent. The classifier fit_b is validated. 















